spring:
  # 数据源配置
  datasource:
    type: com.zaxxer.hikari.HikariDataSource
    driver-class-name: com.p6spy.engine.spy.P6SpyDriver
    jdbc-url: jdbc:p6spy:mysql://localhost:3306/schedule?useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=false&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true
    username: root
    password: root
    # HikariCP配置
    hikari:
      # 连接池名称
      pool-name: HikariCP-Pool
      # 最小空闲连接数
      minimum-idle: 5
      # 连接池最大连接数
      maximum-pool-size: 10
      # 空闲连接存活最大时间，默认10分钟
      idle-timeout: 600000
      # 连接最大存活时间，默认30分钟
      max-lifetime: 1800000
      # 连接超时时间，默认30秒
      connection-timeout: 30000
      # 测试连接是否可用的查询语句
      connection-test-query: SELECT 1
      # 自动提交
      auto-commit: true
  
  # Kafka配置
  kafka:
    bootstrap-servers: localhost:29092,localhost:39092,localhost:49092
    producer:
      # 发生错误后的重试次数
      retries: 3
      # 批量发送的消息数量
      batch-size: 16384
      # 32MB的批处理缓冲区
      buffer-memory: 33554432
      # key序列化方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # value序列化方式
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # acks=0 ： 生产者在成功写入消息之前不会等待任何来自服务器的响应。
      # acks=1 ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应。
      # acks=all ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
      acks: all
    consumer:
      # 默认的消费组ID
      group-id: ${spring.application.name}
      # 是否自动提交offset
      enable-auto-commit: true
      # 提交offset延时(接收到消息后多久提交offset)
      auto-commit-interval: 1000ms
      # key的解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # value的解码方式
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 在偏移量无效的情况下，消费者将从最早的记录开始读取数据（从头开始消费）
      auto-offset-reset: earliest
      # 一次调用poll()操作时返回的最大记录数
      max-poll-records: 500
      # 批量消费的等待时间
      fetch-max-wait: 5000ms
      # 批量消费最小数据量
      fetch-min-size: 1
      # 心跳时间
      heartbeat-interval: 3000ms
      # 服务器等待消费者心跳的最长时间
      session-timeout: 10000
  # Liquibase配置
  liquibase:
    # 配置文件路径
    change-log: classpath:/db/changelog/db.changelog-master.xml
    # 检查变更的间隔时间，默认关闭
    # 数据库schema
    default-schema: schedule
    # 是否在启动时执行更新
    drop-first: false
    # 是否在启动时清空数据库
    clear-checksums: false
    # 用于跟踪变更历史的表名
    database-change-log-table: DATABASE_CHANGE_LOG
    # 用于跟踪变更锁的表名
    database-change-log-lock-table: DATABASE_CHANGE_LOG_LOCK
    # 变更上下文
    contexts: dev
    # 是否在执行迁移时进行测试运行
    test-rollback-on-update: false
    # 是否启用
    enabled: true
    # 数据库连接信息
    url: ${spring.datasource.jdbc-url}
    user: ${spring.datasource.username}
    password: ${spring.datasource.password}
    driver-class-name: ${spring.datasource.driver-class-name}
  jpa:
    show-sql: true
    properties:
      hibernate:
        format_sql: true
        cache:
#          use_second_level_cache: true
        generate_statistics: true
    database-platform: org.hibernate.dialect.MySQL8Dialect
    hibernate:
      ddl-auto: create-drop
  application:
    name: schedule-engine
server:
  port: 10001
